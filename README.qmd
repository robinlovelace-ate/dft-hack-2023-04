---
format: gfm
title: "Notes from a hackathon"
---

Notes from a hackathon.

# Introduction

This is a collection of notes from a hackathon held at the Alan Turing Institute in London on 2023-04-20.

# Setup

## Getting the code repos

The starting point was two code repos:

- Front end (note the use of PMTiles): https://github.com/ADD-William-WaltersDavis/planning_tool
- Backend code in Rust to get scores and routes for each square: https://github.com/adam-jb/rust_connectivity_pt_tiles

These repos were cloned from GitHub as follows:

```{bash}
#| eval: false
gh repo clone ADD-William-WaltersDavis/planning_tool
gh repo clone adam-jb/rust_connectivity_pt_tiles

# add the submodules
git submodule add https://github.com/ADD-William-WaltersDavis/planning_tool planning_tool
git submodule add https://github.com/adam-jb/rust_connectivity_pt_tiles rust_connectivity_pt_tiles
```

## Visualising the data


```{bash}
ls planning_tool
```

Run the front end:

```{bash}
#| eval: false
cd planning_tool
npm install
# global install of vite:
sudo npm install -g vite
npm run dev
```

```{bash}
```


# Working with link data

A starting point was files prepared for the event.
These were copied to the route of the project with bash as follows:

```{bash}
#| eval: false
mkdir data
mv -v ~/Downloads/*.pickle data
```

```{python}
#| eval: false
#| echo: false
# move all pickle files from ~/Downloads to ./data:
import os
import shutil
# Create the data directory if it doesn't exist:
if not os.path.exists('./data'):
    os.makedirs('./data')
for file in os.listdir('~/Downloads'):
    if file.endswith('.pickle'):
        shutil.move(os.path.join('~/Downloads', file), './data')
```

We can list the pickle files as follows:

```{python}
import os
# List pickle files in route directory:
for file in os.listdir('data'):
    print(file)
```


```{python}
import pickle
# Read the first pickle file:
with open('data/AA_example_links.pickle', 'rb') as f:
    links = pickle.load(f)
```

Show what's in the links object, with output showning first 80 characters:

```{python}
# Find length of links:
len(links)
links.__class__
links.__sizeof__()
links_items = links.items()
links_items.__class__
# links_items[:10]
# Convert dict to list:
links_list = list(links_items)
links_list.__class__
len(links_list)
# Convert list to character string:
links_str = str(links_list)
links_str[:80]

```

We converted the object to json as follows:

```{python}
# Define a function that converts the dict to json and save the output to a file:
import json
def write_json(data, filename='data/AA_example_links.json'):
    with open(filename,'w') as f:
        json.dump(data, f, indent=4)

write_json(links, 'data/AA_example_links.json')
```

Test reading as a GeoJSON file:

```{python}
#| eval: false
import geopandas as gpd
# The following fails with error:
gdf = gpd.read_file('data/AA_example_links.json')
```

## Read and visualise with R

We'll use the following packages:

```{r}
library(sf)
library(tmap)
tmap_mode("view")
```

```{r}
```

```{r}
gdf_list = jsonlite::read_json("data/AA_example_links.json")
str(gdf_list[[1]][[1]])
length(gdf_list)
# show 1st element:
length(gdf_list[[1]])
gdf_list[[1]][[1]]
# create geographic representation of first file:
gdf_origin_coords = c(
    gdf_list[[1]][[1]][[8]][[1]],
    gdf_list[[1]][[1]][[8]][[2]]
    )
gdf_destination_coords = c(
    gdf_list[[1]][[1]][[9]][[1]],
    gdf_list[[1]][[1]][[9]][[2]]
    )
gdf_matrix = rbind(gdf_origin_coords, gdf_destination_coords)
gdf_linestring = sf::st_linestring(gdf_matrix)
sfc_linestring = sf::st_sfc(gdf_linestring)
sf_linestring = sf::st_as_sf(sfc_linestring)
qtm(sf_linestring)
```

## Iterate for all links and visualise network

```{r}
```

```{python}
```


```{python}
#| eval: false
#| echo: false
# Print first 10 characters of links:
links[:10]
# Unhashable type: 'slice'
```

```{python}
```

```{python}
```

```{python}